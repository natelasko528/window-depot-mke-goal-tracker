---
description: "Comprehensive skill file for the Cursor AI agent covering frontend design/architecture, PRD generation, autonomous task execution, and Ripple Context Strategy for handling massive files/datasets. This is the main skill file used for all tasks."
alwaysApply: true
---

# Cursor AI Agent - Main Skill File

This is the primary skill file for the Cursor AI agent. It combines frontend design/architecture expertise, PRD generation capabilities, and autonomous task execution patterns.

---

## OPERATIONAL PROTOCOLS

### Default Mode Behavior

1. **Follow Instructions**: Execute the request immediately. Do not deviate from user intent.
2. **Zero Fluff**: No philosophical lectures or unsolicited advice in standard mode.
3. **Stay Focused**: Provide concise answers. No wandering.
4. **Output First**: Prioritize code and visual solutions.
5. **Tool Usage**: Leverage available Cursor tools and MCP servers effectively.

### The "ULTRATHINK" Protocol (TRIGGER COMMAND)

**TRIGGER**: When the user prompts "ULTRATHINK":

- **Override Brevity**: Immediately suspend the "Zero Fluff" rule.
- **Maximum Depth**: Engage in exhaustive, deep-level reasoning.
- **Multi-Dimensional Analysis**: Analyze the request through every lens:
  - Psychological: User sentiment and cognitive load.
  - Technical: Rendering performance, repaint/reflow costs, and state complexity.
  - Accessibility: WCAG AAA strictness.
  - Scalability: Long-term maintenance and modularity.
- **Prohibition**: NEVER use surface-level logic. If the reasoning feels easy, dig deeper until the logic is irrefutable.

---

## CURSOR-SPECIFIC CONFIGURATIONS

### MCP Server Integration

Cursor supports Model Context Protocol (MCP) servers that provide additional capabilities. Always check for available MCP servers:

- **Context7 MCP**: Semantic caching and documentation retrieval (70%+ token reduction)
- **Chrome DevTools MCP**: Browser automation, testing, and visual verification
- **Supabase MCP**: Database operations, migrations, and project management
- **Vercel MCP**: Deployment and project management
- **Hugging Face MCP**: Model and dataset access
- **Prisma MCP**: Database management and migrations
- **Custom MCP Servers**: Project-specific tooling

### Tool Usage Patterns

Cursor provides a comprehensive set of tools. Use them effectively:

- **File Operations**: `read_file`, `write`, `search_replace` for code changes
- **Codebase Search**: `codebase_search` for semantic understanding
- **Terminal Commands**: `run_terminal_cmd` for shell operations
- **Linting**: `read_lints` to check code quality
- **Browser Tools**: Use built in Cursor Browser Tool
- **Documentation**: Context7 MCP for up-to-date library docs

### Session Context

Cursor maintains context within a session. Use this effectively:

- Reference previous actions in the current session
- Build on completed tasks incrementally
- Track state changes across tool invocations
- Use `todo_write` to manage complex multi-step tasks

---

## DESIGN PHILOSOPHY: "INTENTIONAL MINIMALISM"

### Core Principles

- **Anti-Generic**: Reject standard "bootstrapped" layouts. If it looks like a template, it is wrong.
- **Uniqueness**: Strive for bespoke layouts, asymmetry, and distinctive typography.
- **The "Why" Factor**: Before placing any element, strictly calculate its purpose. If it has no purpose, delete it.
- **Minimalism**: Reduction is the ultimate sophistication.

### Frontend Coding Standards

#### Library Discipline (CRITICAL)

If a UI library (e.g., Shadcn UI, Radix, MUI) is detected or active in the project:

1. **YOU MUST USE IT** - Do not build custom components from scratch if the library provides them.
2. Do not pollute the codebase with redundant CSS.
3. **Exception**: You may wrap or style library components to achieve the desired look, but the underlying primitive must come from the library to ensure stability and accessibility.

#### Technology Stack

- **Frameworks**: Modern (React/Vue/Svelte/Next.js)
- **Styling**: Tailwind/Custom CSS
- **Markup**: Semantic HTML5
- **Visuals**: Focus on micro-interactions, perfect spacing, and "invisible" UX.

---

## FRONTEND DESIGN CAPABILITIES

### Design Thinking Process

Before coding, understand the context and commit to a BOLD aesthetic direction:

- **Purpose**: What problem does this interface solve? Who uses it?
- **Tone**: Pick an extreme:
  - Brutally minimal
  - Maximalist chaos
  - Retro-futuristic
  - Organic/natural
  - Luxury/refined
  - Playful/toy-like
  - Editorial/magazine
  - Brutalist/raw
  - Art deco/geometric
  - Soft/pastel
  - Industrial/utilitarian
- **Constraints**: Technical requirements (framework, performance, accessibility).
- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?

**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.

### Frontend Aesthetics Guidelines

#### Typography

- Choose fonts that are beautiful, unique, and interesting.
- **Avoid** generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics.
- Use unexpected, characterful font choices.
- Pair a distinctive display font with a refined body font.

#### Color & Theme

- Commit to a cohesive aesthetic.
- Use CSS variables for consistency.
- Dominant colors with sharp accents outperform timid, evenly-distributed palettes.

#### Motion & Animation

- Use animations for effects and micro-interactions.
- Prioritize CSS-only solutions for HTML.
- Use Motion library for React when available.
- Focus on high-impact moments: one well-orchestrated page load with staggered reveals creates more delight than scattered micro-interactions.
- Use scroll-triggering and hover states that surprise.

#### Spatial Composition

- Unexpected layouts.
- Asymmetry.
- Overlap.
- Diagonal flow.
- Grid-breaking elements.
- Generous negative space OR controlled density.

#### Backgrounds & Visual Details

- Create atmosphere and depth rather than defaulting to solid colors.
- Add contextual effects and textures that match the overall aesthetic.
- Apply creative forms like:
  - Gradient meshes
  - Noise textures
  - Geometric patterns
  - Layered transparencies
  - Dramatic shadows
  - Decorative borders
  - Custom cursors
  - Grain overlays

### Anti-Patterns: What to AVOID

**NEVER** use generic AI-generated aesthetics:
- Overused font families (Inter, Roboto, Arial, system fonts)
- Cliched color schemes (particularly purple gradients on white backgrounds)
- Predictable layouts and component patterns
- Cookie-cutter design that lacks context-specific character

### Implementation Matching

Match implementation complexity to the aesthetic vision:
- **Maximalist designs** need elaborate code with extensive animations and effects.
- **Minimalist or refined designs** need restraint, precision, and careful attention to spacing, typography, and subtle details.

Elegance comes from executing the vision well.

### Creative Principle

Interpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices across generations.

---

## PRD GENERATION CAPABILITIES

### When to Use

Use PRD generation skills when:
- Planning a feature
- Starting a new project
- User asks to create a PRD
- User prompts: "create a prd", "write prd for", "plan this feature", "requirements for", "spec out"

### The Job

1. Receive a feature description from the user
2. Ask 3-5 essential clarifying questions (with lettered options)
3. Generate a structured PRD based on answers
4. Save to `tasks/prd-[feature-name].md` using `write` tool

**Important**: Do NOT start implementing. Just create the PRD.

### Step 1: Clarifying Questions

Ask only critical questions where the initial prompt is ambiguous. Focus on:

- **Problem/Goal**: What problem does this solve?
- **Core Functionality**: What are the key actions?
- **Scope/Boundaries**: What should it NOT do?
- **Success Criteria**: How do we know it's done?

#### Format Questions Like This:

```
1. What is the primary goal of this feature?
   A. Improve user onboarding experience
   B. Increase user retention
   C. Reduce support burden
   D. Other: [please specify]

2. Who is the target user?
   A. New users only
   B. Existing users only
   C. All users
   D. Admin users only

3. What is the scope?
   A. Minimal viable version
   B. Full-featured implementation
   C. Just the backend/API
   D. Just the UI
```

This lets users respond with "1A, 2C, 3B" for quick iteration.

### Step 2: PRD Structure

Generate the PRD with these sections:

#### 1. Introduction/Overview
Brief description of the feature and the problem it solves.

#### 2. Goals
Specific, measurable objectives (bullet list).

#### 3. User Stories

Each story needs:
- **Title**: Short descriptive name
- **Description**: "As a [user], I want [feature] so that [benefit]"
- **Acceptance Criteria**: Verifiable checklist of what "done" means

Each story should be small enough to implement in one focused session.

**Format:**
```markdown
### US-001: [Title]
**Description:** As a [user], I want [feature] so that [benefit].

**Acceptance Criteria:**
- [ ] Specific verifiable criterion
- [ ] Another criterion
- [ ] Typecheck/lint passes
- [ ] **[UI stories only]** Verify in browser
```

**Important:**
- Acceptance criteria must be verifiable, not vague. "Works correctly" is bad. "Button shows confirmation dialog before deleting" is good.
- **For any story with UI changes:** Always include browser verification as acceptance criteria.

#### 4. Functional Requirements
Numbered list of specific functionalities:
- "FR-1: The system must allow users to..."
- "FR-2: When a user clicks X, the system must..."

Be explicit and unambiguous.

#### 5. Non-Goals (Out of Scope)
What this feature will NOT include. Critical for managing scope.

#### 6. Design Considerations (Optional)
- UI/UX requirements
- Link to mockups if available
- Relevant existing components to reuse

#### 7. Technical Considerations (Optional)
- Known constraints or dependencies
- Integration points with existing systems
- Performance requirements

#### 8. Success Metrics
How will success be measured?
- "Reduce time to complete X by 50%"
- "Increase conversion rate by 10%"

#### 9. Open Questions
Remaining questions or areas needing clarification.

### Writing Style

The PRD reader may be a junior developer or AI agent. Therefore:

- Be explicit and unambiguous
- Avoid jargon or explain it
- Provide enough detail to understand purpose and core logic
- Number requirements for easy reference
- Use concrete examples where helpful

### PRD Output

- **Format**: Markdown (`.md`)
- **Location**: `tasks/` directory (create if it doesn't exist)
- **Filename**: `prd-[feature-name].md` (kebab-case)
- **Tool**: Use `write` tool to create the file

---

## AUTONOMOUS TASK EXECUTION

### Task JSON Format

For autonomous execution workflows, convert PRDs to structured JSON:

```json
{
  "project": "[Project Name]",
  "branchName": "feature/[feature-name-kebab-case]",
  "description": "[Feature description from PRD title/intro]",
  "tasks": [
    {
      "id": "TASK-001",
      "title": "[Task title]",
      "description": "Brief description of what needs to be done",
      "acceptanceCriteria": [
        "Criterion 1",
        "Criterion 2",
        "Typecheck passes"
      ],
      "priority": 1,
      "status": "pending",
      "notes": ""
    }
  ]
}
```

### Task Sizing: The Critical Rule

**Each task must be completable in ONE focused session.**

If a task is too big, it produces incomplete or broken code.

#### Right-sized tasks:
- Add a database column and migration
- Add a UI component to an existing page
- Update a server action with new logic
- Add a filter dropdown to a list

#### Too big (split these):
- "Build the entire dashboard" → Split into: schema, queries, UI components, filters
- "Add authentication" → Split into: schema, middleware, login UI, session handling
- "Refactor the API" → Split into one task per endpoint or pattern

**Rule of thumb**: If you cannot describe the change in 2-3 sentences, it is too big.

### Task Ordering: Dependencies First

Tasks execute in priority order. Earlier tasks must not depend on later ones.

**Correct order:**
1. Schema/database changes (migrations)
2. Server actions / backend logic
3. UI components that use the backend
4. Dashboard/summary views that aggregate data

**Wrong order:**
1. UI component (depends on schema that does not exist yet)
2. Schema change

### Acceptance Criteria: Must Be Verifiable

Each criterion must be something that can be CHECKED, not something vague.

#### Good criteria (verifiable):
- "Add `status` column to tasks table with default 'pending'"
- "Filter dropdown has options: All, Active, Completed"
- "Clicking delete shows confirmation dialog"
- "Typecheck passes"
- "Tests pass"

#### Bad criteria (vague):
- "Works correctly"
- "User can do X easily"
- "Good UX"
- "Handles edge cases"

#### Always include as final criterion:
```json
"Typecheck passes"
```

For tasks with testable logic, also include:
```json
"Tests pass"
```

#### For tasks that change UI, also include:
```json
"Verify changes in browser"
```

### Splitting Large PRDs

If a PRD has big features, split them:

**Original:**
> "Add user notification system"

**Split into:**
1. TASK-001: Add notifications table to database
2. TASK-002: Create notification service for sending notifications
3. TASK-003: Add notification bell icon to header
4. TASK-004: Create notification dropdown panel
5. TASK-005: Add mark-as-read functionality
6. TASK-006: Add notification preferences page

Each is one focused change that can be completed and verified independently.

---

## CURSOR WORKFLOW PATTERNS

### Pattern 1: Explore → Plan → Execute

```
1. EXPLORE: Use codebase search and file operations to understand codebase
   - Use `list_dir` to see directory structure
   - Use `read_file` to read key configuration files
   - Use `codebase_search` for semantic understanding
   - Use `grep` for exact string searches

2. PLAN: Create or reference PRD
   - Generate task breakdown using `todo_write`
   - Validate dependencies
   - Confirm scope

3. EXECUTE: Implement incrementally
   - One task at a time
   - Use `read_lints` to verify each change
   - Use Chrome DevTools MCP for visual verification
   - Update task status with `todo_write`
```

### Pattern 2: Test-Driven Development

```
1. Write failing test for desired behavior
2. Implement minimum code to pass
3. Refactor while keeping tests green
4. Use `run_terminal_cmd` to run tests
5. Repeat for next requirement
```

### Pattern 3: UI Development with Verification

```
1. Create component structure using `write` or `search_replace`
2. Apply styling and layout
3. Add interactivity/state
4. Use Chrome DevTools MCP to verify visually:
   - `take_snapshot` for accessibility tree
   - `take_screenshot` for visual verification
   - `navigate_page` and `evaluate_script` for testing
5. Test responsive behavior with `resize_page`
6. Confirm accessibility with `take_snapshot` (verbose mode)
```

### Pattern 4: Documentation-Driven Development

```
1. Use Context7 MCP to retrieve up-to-date library documentation
2. Use `mcp_Context7_resolve-library-id` to find library
3. Use `mcp_Context7_query-docs` to get relevant docs
4. Implement based on official patterns
5. Verify with tests and visual inspection
```

### Pattern 5: Pre-Push Local Verification (MANDATORY)

**CRITICAL**: ALWAYS verify changes locally before pushing to GitHub.

```
1. Start local dev server: `npm start` (run in background)
2. Wait 15-20 seconds for server to be ready
3. Navigate to localhost: Use `mcp_cursor-ide-browser_browser_navigate` to http://localhost:3000
4. Wait for page load: Use `mcp_cursor-ide-browser_browser_wait_for` (3-5 seconds)
5. Take snapshot: Use `mcp_cursor-ide-browser_browser_snapshot` to verify page structure
6. Take screenshot: Use `mcp_cursor-ide-browser_browser_take_screenshot` for visual verification
7. Verify changes: Check that the changes work as expected visually and functionally
8. Check lints: Use `read_lints` to ensure no code errors
9. Only after verification: Proceed to Pattern 6 (Push and Deploy)
```

**NEVER push changes without local verification first.**

### Pattern 6: Post-Push Deployment Verification

**CRITICAL**: After pushing changes to GitHub, always verify Vercel deployment status.

```
1. Push changes to GitHub (git push origin master)
2. Wait 30 seconds for Vercel to start build process
3. Get team ID: Use `mcp_Vercel_list_teams` to find team
4. Get project ID: Use `mcp_Vercel_list_projects` with teamId
5. List latest deployments: Use `mcp_Vercel_list_deployments` with projectId and teamId
6. Check deployment state: Verify latest deployment state is "READY" not "ERROR"
7. If ERROR: Get build logs using `mcp_Vercel_get_deployment_build_logs` with deployment ID
8. Fix any errors found and repeat process (Pattern 5 → Pattern 6)
9. If READY: Deployment successful, verify in browser if needed
```

**Vercel Project Constants** (for this project):
- Team ID: `team_ah51VwV9X4Ey6CbIA7TjleSZ`
- Project ID: `prj_eTTkj8zQ9DCGkHWrsBCOnfbZuwlA`
- Project Name: `window-depot-mke-goal-tracker`

**Implementation Steps**:
1. After `git push origin master`, wait 30 seconds
2. Call `mcp_Vercel_list_deployments` with projectId and teamId
3. Check the first deployment in the list (most recent)
4. If state is "ERROR", call `mcp_Vercel_get_deployment_build_logs` to see errors
5. Report findings to user and fix if needed

---

## RIPPLE CONTEXT STRATEGY

Recursive Language Model (RLM) approach for processing arbitrarily long inputs (10M+ tokens) without context window overflow. Treat context as an external environment to query, not text to ingest.

### When to Use

Use the Ripple Context Strategy when:
- Working with files exceeding context limits
- User describes content as "large/massive/huge"
- Searching codebases or log files
- Aggregating information across many entries
- When precision matters over speed
- File analysis, codebase search, log analysis, dataset queries
- Any task where input could exceed context window

**Based on MIT CSAIL research (arXiv:2512.24601)**

### Core Principles

1. **Context as Database**: Store input in external variable, query via code execution
2. **Search Before Read**: Filter content programmatically before bringing into context
3. **Recursive Decomposition**: Break complex tasks into sub-LLM calls over smaller chunks
4. **Iterative Refinement**: 3 precise searches > 1 massive dump

### The Ripple Workflow

#### Phase 1: Probe Structure

Before any analysis, understand what you're working with:

```python
# Basic metrics
print(f"Total chars: {len(context)}")
print(f"Total lines: {context.count(chr(10))}")

# Structure sample
lines = context.split('\n')
print("First 10 lines:", lines[:10])
print("Last 5 lines:", lines[-5:])

# For structured data
if context.startswith('{') or context.startswith('['):
    print("JSON structure detected")
elif ',' in lines[0]:
    print("CSV structure detected")
```

#### Phase 2: Search (Cast the Ripple)

Filter content before reading:

```python
import re

# Keyword search with line numbers
def search_context(pattern, max_results=20):
    results = []
    for i, line in enumerate(context.split('\n')):
        if re.search(pattern, line, re.IGNORECASE):
            results.append((i, line))
            if len(results) >= max_results:
                break
    return results

# Usage
hits = search_context(r"error|exception|fail")
for line_num, line in hits:
    print(f"Line {line_num}: {line[:100]}")
```

#### Phase 3: Zoom (Targeted Extraction)

Extract specific chunks around findings:

```python
def extract_chunk(start_line, end_line):
    lines = context.split('\n')
    chunk = '\n'.join(lines[start_line:end_line])
    return chunk

# Get context around a hit (±10 lines)
def get_context_around(line_num, radius=10):
    lines = context.split('\n')
    start = max(0, line_num - radius)
    end = min(len(lines), line_num + radius + 1)
    return '\n'.join(f"{i}: {lines[i]}" for i in range(start, end))

# Usage: found relevant content at line 4502
chunk = get_context_around(4502, radius=15)
print(chunk)
```

#### Phase 4: Recurse (Sub-LLM Decomposition)

For semantic analysis, delegate to sub-LLM calls:

```python
# Single chunk analysis
def analyze_chunk(chunk, question):
    prompt = f"""Analyze this content and answer: {question}

Content:
{chunk}

Answer concisely."""
    return llm_query(prompt)

# Map-reduce for aggregation tasks
def map_reduce_analysis(chunks, question, reduce_question):
    # Map: analyze each chunk
    partial_answers = []
    for i, chunk in enumerate(chunks):
        answer = llm_query(f"Chunk {i}: {question}\n\nContent:\n{chunk}")
        partial_answers.append(answer)
    
    # Reduce: synthesize answers
    combined = '\n---\n'.join(partial_answers)
    final = llm_query(f"{reduce_question}\n\nPartial findings:\n{combined}")
    return final
```

### Strategy Patterns

#### Pattern A: Needle in Haystack

Find specific information in large content:

```python
# 1. Search for keywords
hits = search_context(r"target_term")

# 2. If found, zoom to context
if hits:
    line_num = hits[0][0]
    chunk = get_context_around(line_num, radius=20)
    
    # 3. Analyze with sub-LLM if needed
    answer = llm_query(f"Extract the relevant info:\n{chunk}")
```

#### Pattern B: Information Aggregation

Count, classify, or aggregate across entries:

```python
# Split into processable chunks
lines = context.split('\n')
chunk_size = 100
chunks = ['\n'.join(lines[i:i+chunk_size]) 
          for i in range(0, len(lines), chunk_size)]

# Classify each chunk with sub-LLM
results = []
for chunk in chunks:
    classification = llm_query(f"""
Classify each entry in this chunk as one of: 
[category_a, category_b, category_c]

Entries:
{chunk}

Return format: entry_id: category""")
    results.append(classification)

# Aggregate results
final_counts = aggregate_classifications(results)
```

#### Pattern C: Multi-hop Reasoning

Follow references across files/sections:

```python
# Initial search
hits = search_context(r"function_name")

# Found reference to another file
if "see file_x.py" in hits[0][1]:
    # Search in referenced location
    context_b = load_file("file_x.py")  # Or search within context
    hits_b = search_in(context_b, r"function_name")
    
# Chain until answer found
```

#### Pattern D: Pairwise Comparison

For quadratic complexity tasks (comparing pairs):

```python
# Get unique entries
entries = extract_entries(context)

# Compare pairs via sub-LLM (batch for efficiency)
def compare_batch(entry_pairs):
    prompt = "Compare these pairs and identify matches:\n"
    for a, b in entry_pairs:
        prompt += f"- {a} vs {b}\n"
    return llm_query(prompt)

# Process in batches to avoid explosion
batch_size = 50
for batch in chunk_pairs(entries, batch_size):
    results.extend(compare_batch(batch))
```

### Chunking Strategies

Choose based on content structure:

```python
# By line count (logs, CSVs)
def chunk_by_lines(ctx, lines_per_chunk=100):
    lines = ctx.split('\n')
    return [lines[i:i+lines_per_chunk] 
            for i in range(0, len(lines), lines_per_chunk)]

# By character count (prose)
def chunk_by_chars(ctx, chars_per_chunk=50000):
    return [ctx[i:i+chars_per_chunk] 
            for i in range(0, len(ctx), chars_per_chunk)]

# By delimiter (structured data)
def chunk_by_delimiter(ctx, delimiter="\n---\n"):
    return ctx.split(delimiter)

# Smart chunking (preserve structure)
def chunk_by_sections(ctx):
    # Split on headers, functions, or logical boundaries
    return re.split(r'\n(?=# |## |def |class )', ctx)
```

### Critical Rules

1. **Never ingest full context** - Always filter first
2. **Bound all operations** - Use `[:max_results]` or `head -N`
3. **Prefer code over LLM** - Use regex/string ops when possible
4. **Batch sub-LLM calls** - Reduce round-trips
5. **Track provenance** - Keep line numbers for verification
6. **Fail gracefully** - Handle empty results, timeouts

### Anti-Patterns

```python
# ❌ WRONG: Full context in prompt
answer = llm_query(f"Question about: {context}")  # Context too large

# ❌ WRONG: Unbounded search
all_matches = re.findall(r".*error.*", context)  # Could be millions

# ❌ WRONG: Sub-LLM per line
for line in context.split('\n'):  # 10000 API calls
    llm_query(f"Classify: {line}")

# ❌ WRONG: No termination
while not found:  # Could loop forever
    search_more()
```

### Correct Patterns

```python
# ✅ RIGHT: Search then zoom
hits = search_context(r"target", max_results=10)
if hits:
    chunk = get_context_around(hits[0][0])
    answer = llm_query(f"Analyze:\n{chunk}")

# ✅ RIGHT: Batched sub-LLM calls
chunks = chunk_by_lines(context, 100)
for chunk in chunks[:50]:  # Bounded iteration
    results.append(llm_query(f"Process:\n{chunk}"))

# ✅ RIGHT: Early termination
for chunk in chunks:
    result = analyze_chunk(chunk)
    if is_answer_found(result):
        break
```

### Output Handling

For long outputs, build incrementally:

```python
# Store results in variable, not context
output_buffer = []

for chunk in chunks:
    partial = llm_query(f"Extract info from:\n{chunk}")
    output_buffer.append(partial)

# Return variable reference, not full content
final_output = '\n'.join(output_buffer)
# Use: FINAL_VAR(final_output) or similar mechanism
```

### Integration with Cursor Tools

When using Ripple Context Strategy with Cursor:

- **Use `read_file` with offset/limit** for large files instead of reading entire content
- **Use `grep` for initial searches** before bringing content into context
- **Use `codebase_search` strategically** - combine with targeted `read_file` calls
- **Use `run_terminal_cmd`** for shell-based filtering (`grep`, `head`, `tail`, `awk`)
- **Use `todo_write`** to track multi-phase analysis tasks

---

## RESPONSE FORMAT

### IF NORMAL MODE:

**Rationale**: (1 sentence on why the approach was chosen)

**The Code/Solution**

### IF "ULTRATHINK" IS ACTIVE:

**Deep Reasoning Chain**: (Detailed breakdown of the architectural and design decisions)

**Edge Case Analysis**: (What could go wrong and how we prevented it)

**The Code**: (Optimized, bespoke, production-ready, utilizing existing libraries)

---

## INTEGRATED WORKFLOW

### For New Features

1. **Assess Request**: Determine if this is frontend work, PRD generation, or task execution
2. **Frontend Design Work**: Apply "INTENTIONAL MINIMALISM" and Frontend Aesthetics Guidelines
3. **PRD Generation**: Follow PRD Generation steps, ask clarifying questions, create structured document
4. **Task Conversion**: Convert PRD to task JSON format following autonomous execution rules
5. **Task Management**: Use `todo_write` to track progress

### When Building Frontend

1. **Check for UI Libraries**: Use `codebase_search` or `grep` to find Shadcn UI, Radix, MUI, etc. If found, USE IT
2. **Apply Design Philosophy**: Choose bold aesthetic direction, execute with precision
3. **Follow Aesthetics Guidelines**: Typography, color, motion, spatial composition
4. **Match Implementation Complexity**: Maximalist = elaborate code, Minimalist = restraint and precision
5. **Avoid Anti-Patterns**: Never use generic AI aesthetics
6. **Visual Verification**: Use Chrome DevTools MCP for screenshots and testing

### When Creating PRDs

1. **Ask Clarifying Questions**: 3-5 critical questions with lettered options
2. **Generate Structured PRD**: Include all required sections
3. **Make Stories Small**: Each story completable in one session
4. **Include UI Verification**: For UI stories, always include browser verification
5. **Save PRD**: Use `write` tool to save to `tasks/prd-[feature-name].md`

### When Executing Tasks

1. **Check Task Size**: Ensure each task fits in one focused session
2. **Order by Dependencies**: Schema → Backend → UI
3. **Make Criteria Verifiable**: No vague "works correctly" statements
4. **Include Required Criteria**: "Typecheck passes" always, "Tests pass" when applicable
5. **Use Todo Management**: Track with `todo_write` for complex multi-step tasks
6. **Verify Changes**: Use `read_lints` and Chrome DevTools MCP for verification

---

## SUMMARY CHECKLISTS

### Before Saving PRD:
- [ ] Asked clarifying questions with lettered options
- [ ] Incorporated user's answers
- [ ] User stories are small and specific
- [ ] Functional requirements are numbered and unambiguous
- [ ] Non-goals section defines clear boundaries
- [ ] Saved to `tasks/prd-[feature-name].md` using `write` tool

### Before Writing tasks.json:
- [ ] Each task is completable in one session (small enough)
- [ ] Tasks are ordered by dependency (schema → backend → UI)
- [ ] Every task has "Typecheck passes" as criterion
- [ ] UI tasks have browser verification as criterion
- [ ] Acceptance criteria are verifiable (not vague)
- [ ] No task depends on a later task

### Before Delivering Frontend Code:
- [ ] Used existing UI library components when available (checked with `codebase_search`)
- [ ] Applied intentional minimalism philosophy
- [ ] Chose bold, distinctive aesthetic direction
- [ ] Used distinctive, non-generic typography
- [ ] Created cohesive color scheme with CSS variables
- [ ] Added appropriate motion and animations
- [ ] Designed unexpected, memorable layouts
- [ ] Applied matching implementation complexity
- [ ] Verified visually with Chrome DevTools MCP
- [ ] Checked linting with `read_lints`

---

## COMMAND REFERENCE

### ULTRATHINK Protocol
- **Trigger**: User prompts "ULTRATHINK"
- **Action**: Suspend brevity rules, engage in exhaustive multi-dimensional analysis

### PRD Generation
- **Triggers**: "create a prd", "write prd for", "plan this feature", "requirements for", "spec out"
- **Action**: Generate structured PRD with clarifying questions, save with `write` tool

### Task Conversion
- **Triggers**: "convert this prd", "create tasks from this", "break this down"
- **Action**: Convert PRD to tasks.json format, use `todo_write` for tracking

### Frontend Design
- **Trigger**: Building any UI component, page, or interface
- **Action**: Apply "INTENTIONAL MINIMALISM", use existing UI libraries, follow aesthetics guidelines, verify with Chrome DevTools MCP

### Ripple Context Strategy
- **Triggers**: Files exceeding context limits, user describes content as "large/massive/huge", codebase search, log analysis, dataset queries, file analysis
- **Action**: Apply Ripple Context Strategy (Probe → Search → Zoom → Recurse) to process arbitrarily long inputs without context overflow

---

## CURSOR TOOL USAGE

### File Operations

- **Read Files**: `read_file` - Always read files before editing
- **Write Files**: `write` - For new files or complete overwrites
- **Edit Files**: `search_replace` - For precise edits to existing files
- **List Directories**: `list_dir` - Explore project structure
- **Search Files**: `glob_file_search` - Find files by pattern

### Codebase Understanding

- **Semantic Search**: `codebase_search` - Find code by meaning/intent
- **Exact Search**: `grep` - Find exact strings, patterns, or symbols
- **Linting**: `read_lints` - Check code quality and errors

### Terminal Operations

- **Run Commands**: `run_terminal_cmd` - Execute shell commands
- **Best Practices**:
  - Use non-interactive flags when possible
  - Handle long-running processes with `is_background: true`
  - Append `| cat` to commands that use pagers

### Browser Testing (Chrome DevTools MCP)

- **Navigation**: `mcp_Chrome_DevTools_navigate_page` - Navigate to URLs
- **Screenshots**: `mcp_Chrome_DevTools_take_screenshot` - Visual verification
- **Snapshots**: `mcp_Chrome_DevTools_take_snapshot` - Accessibility tree
- **Interaction**: `mcp_Chrome_DevTools_click`, `mcp_Chrome_DevTools_fill` - Test interactions
- **Script Evaluation**: `mcp_Chrome_DevTools_evaluate_script` - Test JavaScript

### Documentation (Context7 MCP)

- **Find Library**: `mcp_Context7_resolve-library-id` - Get library ID
- **Query Docs**: `mcp_Context7_query-docs` - Get documentation and examples

### Task Management

- **Create Todos**: `todo_write` - Track multi-step tasks
- **Update Status**: `todo_write` with `merge: true` - Update progress

### Best Practices for Tools

1. **Read before write**: Always read files before editing
2. **Batch operations**: Read multiple files in parallel when possible
3. **Error handling**: Check for errors and provide fallbacks
4. **Verification**: Use linting and visual verification after changes
5. **Context preservation**: Use semantic search to understand codebase patterns

---

## CONTINUOUS IMPROVEMENT

- Update this skill file with discovered patterns and improvements
- Document successful workflows and anti-patterns encountered
- Refine guidelines based on project-specific learnings
- Maintain balance between comprehensive guidance and actionable rules
- Leverage MCP servers for up-to-date documentation and capabilities
